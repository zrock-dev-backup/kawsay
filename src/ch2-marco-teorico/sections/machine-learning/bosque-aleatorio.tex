\subsubsection{Bosques Aleatorios}
El algoritmo de Bosques Aleatorios (Random Forest), introducido por Breiman \cite{breiman2001random}, es un algoritmo de aprendizaje supervisado.
Es un conjunto (ensemble)\footnote{Un \textbf{método de ensamble} (ensemble method) en machine learning combina las predicciones de múltiples modelos base (como árboles de decisión) para producir una predicción final mejor y más robusta que la de cualquier modelo individual.} de árboles de decisión, donde cada árbol se entrena con un subconjunto aleatorio de los datos y un subconjunto aleatorio de las características.
La predicción final se obtiene agregando las predicciones de todos los árboles individuales.
Para tareas de clasificación, esto se hace típicamente por votación mayoritaria, mientras que para tareas de regresión, se utiliza la predicción promedio.

El algoritmo de Bosques Aleatorios aprovecha el principio de la "sabiduría de la multitud", combinando las diversas perspectivas de múltiples árboles de decisión para producir predicciones más precisas y estables que las que pueden proporcionar los árboles individuales.
Los pasos fundamentales involucrados en la construcción de un Bosque Aleatorio son:

\begin{enumerate}
    \item \textbf{Muestreo Bootstrap (Bootstrap Sampling):} El algoritmo selecciona aleatoriamente, con reemplazo, \textit{n} muestras del conjunto de datos de entrenamiento original para crear un conjunto de entrenamiento único para cada árbol.
    Este proceso, denominado bootstrapping, asegura que cada árbol se entrene con un subconjunto de datos ligeramente diferente.
    \item \textbf{Aleatoriedad de Características (Feature Randomness):} Para cada nodo dentro de un árbol, se elige un subconjunto aleatorio de \textit{m} características del total de \textit{p} características disponibles.
    Luego, el algoritmo identifica la división óptima para el nodo basándose en estas \textit{m} características.
    El parámetro \textit{m} es típicamente significativamente más pequeño que \textit{p}, un paso crucial para reducir la correlación\footnote{La \textbf{correlación} entre árboles en un bosque aleatorio se refiere a la tendencia de diferentes árboles a cometer errores similares en las mismas instancias.
Reducir esta correlación es clave para la efectividad del ensamble.} entre los árboles.
    \item \textbf{Crecimiento del Árbol (Tree Growth):} Cada árbol se cultiva hasta su máxima profundidad sin poda\footnote{La \textbf{poda} (pruning) en árboles de decisión es una técnica para reducir el tamaño del árbol eliminando secciones que proporcionan poco poder predictivo, con el fin de evitar el sobreajuste (overfitting).} (o hasta que se alcanza un tamaño mínimo de nodo predefinido).
    Esto permite que cada árbol capture relaciones complejas en sus datos de entrenamiento.
    \item \textbf{Agregación de Predicciones (Prediction Aggregation):} Para problemas de clasificación, la etiqueta de clase final se determina mediante votación mayoritaria entre todos los árboles.
    En escenarios de regresión, la predicción final es el promedio de las predicciones generadas por los árboles individuales.
\end{enumerate}

\paragraph{Ajuste de Hiperparámetros}
es una fase crítica en la optimización del rendimiento de un modelo de Bosques Aleatorios.
Los hiperparámetros clave que impactan significativamente el comportamiento del modelo incluyen:

\begin{itemize}
    \item \texttt{n\_estimators}: El número de árboles dentro del bosque.
    \item \texttt{max\_features}: El número de características consideradas al buscar la mejor división en cada nodo.
    \item \texttt{max\_depth}: La profundidad máxima permitida de los árboles individuales.
    \item \texttt{min\_samples\_split}: El número mínimo de muestras requerido para dividir un nodo interno.
    \item \texttt{min\_samples\_leaf}: El número mínimo de muestras obligatorio para residir en un nodo hoja.
\end{itemize}

Dos metodologías ampliamente utilizadas para el ajuste de hiperparámetros son la Búsqueda en Rejilla (Grid Search) y la Búsqueda Aleatoria (Random Search).

\begin{itemize}
	\item \textbf{Búsqueda en Rejilla (Grid Search):} es una técnica de búsqueda exhaustiva que evalúa sistemáticamente todas las combinaciones posibles de valores de hiperparámetros dentro de una rejilla predefinida \cite{bergstra2012random}.
	El usuario especifica un conjunto discreto de valores para cada hiperparámetro, y la Búsqueda en Rejilla explora meticulosamente cada combinación.

	\item \textbf{Búsqueda Aleatoria (Random Search):} es un método de búsqueda estocástica\footnote{Un \textbf{método estocástico} es aquel que incorpora algún elemento de aleatoriedad en su proceso.} que muestrea aleatoriamente combinaciones de hiperparámetros de distribuciones especificadas \cite{bergstra2012random}.
	A diferencia de la exploración exhaustiva de la Búsqueda en Rejilla, la Búsqueda Aleatoria sondea un subconjunto aleatorio del espacio de hiperparámetros.
\end{itemize}
